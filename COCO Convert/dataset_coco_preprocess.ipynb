{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Process SPEED+ annotations in COCO format\n",
    "\n",
    "COCO format is easily usable in most popular DL codebases. \n",
    "\n",
    "Here, the SPEED+ dataset is converted to COCO format for ease of use in mmcv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from utils import SatellitePoseEstimationDataset\n",
    "from projection import Projection\n",
    "from convert2COCO import COCO_SatPose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_json(json_path):\n",
    "    with open(json_path, 'r') as jf:\n",
    "        d = json.load(jf)\n",
    "    return d\n",
    "    \n",
    "def get_bounding_box(uv_pt,relax_margin = 5):\n",
    "    u_max = max(uv_pt[0])*(1+relax_margin/100)\n",
    "    u_min = min(uv_pt[0])*(1-relax_margin/100)\n",
    "    v_max = max(uv_pt[1])*(1+relax_margin/100)\n",
    "    v_min = min(uv_pt[1])*(1-relax_margin/100)\n",
    "\n",
    "    return [u_min, u_max, v_min, v_max]\n",
    "\n",
    "def process_bounding_boxes(filenames, labels, model_dict, camK, camD):\n",
    "    list_labels = []\n",
    "\n",
    "    feat_keys = list(model_dict)\n",
    "    x_3d = np.ndarray((3,len(feat_keys)))\n",
    "\n",
    "    for i,key in enumerate(feat_keys):\n",
    "        x_3d[:,i] = model_dict[key]\n",
    "\n",
    "    for filename in filenames:\n",
    "        q = labels[filename]['q']\n",
    "        r = labels[filename]['r']\n",
    "        uv_pts = Projection.project_to_image(q, r, camK, camD, r_B=x_3d)\n",
    "        features = []\n",
    "\n",
    "        cam_nu = camK[0,2]*2\n",
    "        cam_nv = camK[1,2]*2\n",
    "\n",
    "        uv_pts = np.array(uv_pts)\n",
    "\n",
    "        for idx in range(uv_pts.shape[1]):\n",
    "            uv = uv_pts[:,idx].tolist()\n",
    "            #TODO: Visibility makes a difference? \n",
    "            # visibility flag v defined as v=0: not labeled (in which case x=y=0), v=1: labeled but not visible, and v=2: labeled and visible\n",
    "            visibility = 0 if uv[0]> cam_nu or uv[0]<0 or uv[1]>cam_nv or uv[1]<0 else 2\n",
    "            feature = {\"ID\": idx, 'Coordinates': uv, 'Visibility': visibility}\n",
    "            features.append(feature)\n",
    "\n",
    "        bbox_limits = get_bounding_box(uv_pts)\n",
    "        bbox_dict = {'filename': filename, 'label':bbox_limits, 'features': features}\n",
    "        list_labels.append(bbox_dict)\n",
    "\n",
    "    return list_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process bounding box and keypoint data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size before: 47966\n",
      "Dataset size after: 19187\n",
      "Dataset size before: 11994\n",
      "Dataset size after: 4798\n"
     ]
    }
   ],
   "source": [
    "dataset_root_dir = '../speedplus/' # path to speed+'\n",
    "camera_file = os.path.join(dataset_root_dir, \"camera.json\")\n",
    "model_3D_file =  os.path.join(dataset_root_dir, \"tango_model_25pt.json\")\n",
    "\n",
    "model3d_data = load_json(model_3D_file)\n",
    "camera_data = load_json(camera_file)\n",
    "\n",
    "K = np.array(camera_data['cameraMatrix']) \n",
    "D = np.array(camera_data['distCoeffs'])\n",
    "\n",
    "dataset = SatellitePoseEstimationDataset(root_dir=dataset_root_dir)\n",
    "labels = dataset.labels\n",
    "\n",
    "bboxes = {}\n",
    "\n",
    "for partition in list(dataset.partitions):\n",
    "    if partition==\"validation\" or partition==\"train\":\n",
    "        filenames = dataset.partitions[partition]\n",
    "        bbox_anns = process_bounding_boxes(filenames, labels, model3d_data, K, D)\n",
    "        bboxes[partition] = bbox_anns\n",
    "\n",
    "## ===================================\n",
    "#  ATTENTION: Create a subset if needed\n",
    "## ====================================\n",
    "create_subset= True\n",
    "\n",
    "subset_fraction=0.4 # Fraction of original set\n",
    "valid_partitions = [\"train\", \"validation\"]\n",
    "\n",
    "new_bboxes = {}\n",
    "if create_subset:\n",
    "    for partition in valid_partitions:\n",
    "        \n",
    "        old_bboxes = bboxes[partition]\n",
    "        print(f\"Dataset size before: {len(old_bboxes)}\")\n",
    "        terminal_idx= int(0.4*len(old_bboxes)) + 1 \n",
    "        \n",
    "        random.shuffle(old_bboxes)\n",
    "        new_bboxes[partition] = old_bboxes[:terminal_idx]\n",
    "        print(f\"Dataset size after: {len(new_bboxes[partition])}\")\n",
    "    \n",
    "    bboxes=new_bboxes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to COCO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11-point wireframe Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tango_KPs_n = 11\n",
    "# tango_skeleton = [[1,2],[2,3],[3,4],[4,1],[1,5],[2,6],[3,7],[4,8],[5,6],[6,7],[7,8],[8,5],[1,9],[2,10],[4,11]]\n",
    "\n",
    "# base_args = {\n",
    "#         \"dataset\":\"SPEED+\",\n",
    "#         \"size\":(1920,1200),\n",
    "#         \"url\": \"\",\n",
    "#         \"n_keypoints\":tango_KPs_n,\n",
    "#         \"skeleton\": tango_skeleton,\n",
    "#         \"extension\": \"jpg\",\n",
    "#         \"img_name_prefix\": \"img\",\n",
    "#         \"img_name_suffix\": \"\"\n",
    "#         }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Images and Annotations\n",
      "1.0 %\n",
      "11.0 %\n",
      "21.0 %\n",
      "31.0 %\n",
      "41.0 %\n",
      "51.0 %\n",
      "61.0 %\n",
      "71.0 %\n",
      "81.0 %\n",
      "91.0 %\n",
      "Processed images and annotations!\n"
     ]
    }
   ],
   "source": [
    "suffix = \"_25pt_subset40_wh\"\n",
    "#TRAIN\n",
    "partition = \"synthetic\"\n",
    "partition_path = f\"../speedplus/{partition}\"\n",
    "subset_name = \"train\"\n",
    "train_args = base_args\n",
    "train_args[\"image_path\"] = os.path.join(partition_path,'images')\n",
    "train_args['data'] = bboxes[subset_name]\n",
    "output_json_path = os.path.join(partition_path,f'train_coco{suffix}.json')\n",
    "\n",
    "\n",
    "train_COCO = COCO_SatPose(**train_args)\n",
    "# train_COCO.write2File(output_json_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Images and Annotations\n",
      "1.0 %\n",
      "11.0 %\n",
      "21.0 %\n",
      "31.0 %\n",
      "41.0 %\n",
      "51.0 %\n",
      "61.0 %\n",
      "71.0 %\n",
      "81.0 %\n",
      "91.0 %\n",
      "Processed images and annotations!\n"
     ]
    }
   ],
   "source": [
    "partition = \"synthetic\"\n",
    "partition_path = f\"../speedplus/{partition}\"\n",
    "subset_name = \"validation\"\n",
    "val_args = base_args\n",
    "val_args[\"image_path\"] = os.path.join(partition_path,'images')\n",
    "val_args['data'] = bboxes[subset_name]\n",
    "output_json_path = os.path.join(partition_path,f'val_coco{suffix}.json')\n",
    "\n",
    "\n",
    "val_COCO = COCO_SatPose(**val_args)\n",
    "# val_COCO.write2File(output_json_path)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b6072fc218d0f1fafe5c80af72eacbb96147ed7768b9128c2228ca420bdcaf8d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
